{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57fd6e23-bdd4-437c-a81c-6b42765fac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import dill\n",
    "import logging\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier,\n",
    "    ExtraTreesClassifier, HistGradientBoostingClassifier\n",
    ")\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "\n",
    "class InferencePreprocessor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Приводит признаки к обученному набору для инференса.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.feature_columns_ = []\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Запоминает признаки обучающей выборки.\"\"\"\n",
    "        self.feature_columns_ = X.columns.tolist()\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        \"\"\"Добавляет недостающие признаки, удаляет лишние, заполняет NaN.\"\"\"\n",
    "        X = X.copy()\n",
    "        for col in self.feature_columns_:\n",
    "            if col not in X.columns:\n",
    "                X[col] = 0\n",
    "        extra_cols = [col for col in X.columns if col not in self.feature_columns_]\n",
    "        X = X.drop(columns=extra_cols, errors='ignore')\n",
    "        X = X.fillna(0)\n",
    "        return X[self.feature_columns_]\n",
    "\n",
    "def initialize_model(model_class, model_name, params):\n",
    "    \"\"\"Инициализация модели с нужными параметрами.\"\"\"\n",
    "    if model_name == \"CatBoost\":\n",
    "        return model_class(**params, silent=True, random_state=42)\n",
    "    if model_name == \"XGBoost\":\n",
    "        return model_class(\n",
    "            **params, objective='multi:softprob',\n",
    "            eval_metric='mlogloss', use_label_encoder=False,\n",
    "            random_state=42\n",
    "        )\n",
    "    if model_name == \"LightGBM\":\n",
    "        return model_class(**params, random_state=42, verbosity=-1)\n",
    "    return model_class(**params, random_state=42)\n",
    "\n",
    "class ModelTrainer:\n",
    "    \"\"\"Обучает модели, сохраняет лучшую по F1-weighted (кросс-валидация) в model.pkl.\"\"\"\n",
    "    def __init__(self, model_dir, param_grids=None, cv=5):\n",
    "        self.model_dir = model_dir\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        self.models = {\n",
    "            \"RandomForest\": RandomForestClassifier,\n",
    "            \"CatBoost\": CatBoostClassifier,\n",
    "            \"LightGBM\": lgb.LGBMClassifier,\n",
    "            \"XGBoost\": xgb.XGBClassifier,\n",
    "            \"ExtraTrees\": ExtraTreesClassifier,\n",
    "            \"HistGradientBoosting\": HistGradientBoostingClassifier,\n",
    "            \"GradientBoosting\": GradientBoostingClassifier\n",
    "        }\n",
    "        self.param_grids = param_grids if param_grids is not None else {}\n",
    "        self.cv = cv\n",
    "\n",
    "    def train_and_save_best(self, train_combined_df, target_column='risk_status',\n",
    "                           columns_to_drop=None):\n",
    "        \"\"\"Обучает все модели, выбирает и сохраняет лучшую.\"\"\"\n",
    "        if columns_to_drop is None:\n",
    "            columns_to_drop = [\n",
    "                'user_id', 'course_id', 'real_course_progress', 'course_success', 'week'\n",
    "            ]\n",
    "        X_train = train_combined_df.drop(\n",
    "            columns=[target_column] + columns_to_drop, errors='ignore'\n",
    "        )\n",
    "        y_train = train_combined_df[target_column]\n",
    "\n",
    "        best_score = -np.inf\n",
    "        best_pipeline = None\n",
    "        best_model_name = None\n",
    "\n",
    "        for model_name, model_class in self.models.items():\n",
    "            logger.info(f\"\\n--- Обучение модели: {model_name} ---\")\n",
    "            pipeline = Pipeline([\n",
    "                ('preprocessor', InferencePreprocessor()),\n",
    "                ('model', initialize_model(model_class, model_name, {}))\n",
    "            ])\n",
    "            param_grid = {\n",
    "                f'model__{k}': v for k, v in\n",
    "                self.param_grids.get(model_name, {}).items()\n",
    "            }\n",
    "            if param_grid:\n",
    "                search = RandomizedSearchCV(\n",
    "                    estimator=pipeline,\n",
    "                    param_distributions=param_grid,\n",
    "                    n_iter=5,\n",
    "                    cv=self.cv,\n",
    "                    scoring='f1_weighted',\n",
    "                    n_jobs=-1,\n",
    "                    random_state=42,\n",
    "                    verbose=1\n",
    "                )\n",
    "                search.fit(X_train, y_train)\n",
    "                score = search.best_score_\n",
    "                pipeline_to_save = search.best_estimator_\n",
    "            else:\n",
    "                scores = cross_val_score(\n",
    "                    pipeline, X_train, y_train,\n",
    "                    cv=self.cv, scoring='f1_weighted', n_jobs=-1\n",
    "                )\n",
    "                score = np.mean(scores)\n",
    "                logger.info(f\"Кросс-валидация f1_weighted: {scores} (mean={score:.4f})\")\n",
    "                pipeline.fit(X_train, y_train)\n",
    "                pipeline_to_save = pipeline\n",
    "\n",
    "            logger.info(f\"F1-weighted для {model_name}: {score:.4f}\")\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_pipeline = pipeline_to_save\n",
    "                best_model_name = model_name\n",
    "\n",
    "        save_path = os.path.join(self.model_dir, 'model.pkl')\n",
    "        with open(save_path, 'wb') as f:\n",
    "            dill.dump(best_pipeline, f)\n",
    "        logger.info(f\"Лучшая модель ({best_model_name}) сохранена в: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0311687-3dd8-4367-a8db-480a825935dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 15:37:14,790 - INFO - \n",
      "--- Обучение модели: RandomForest ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 15:49:13,551 - INFO - F1-weighted для RandomForest: 0.6130\n",
      "2025-07-04 15:49:13,551 - INFO - \n",
      "--- Обучение модели: CatBoost ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 16:08:44,177 - INFO - F1-weighted для CatBoost: 0.6148\n",
      "2025-07-04 16:08:44,195 - INFO - \n",
      "--- Обучение модели: LightGBM ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 17:09:35,047 - INFO - F1-weighted для LightGBM: 0.6135\n",
      "2025-07-04 17:09:35,048 - INFO - \n",
      "--- Обучение модели: XGBoost ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:22:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2025-07-04 17:25:50,513 - INFO - F1-weighted для XGBoost: 0.6150\n",
      "2025-07-04 17:25:50,513 - INFO - \n",
      "--- Обучение модели: ExtraTrees ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 17:32:48,573 - INFO - F1-weighted для ExtraTrees: 0.6142\n",
      "2025-07-04 17:32:48,573 - INFO - \n",
      "--- Обучение модели: HistGradientBoosting ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 17:38:54,924 - INFO - F1-weighted для HistGradientBoosting: 0.6158\n",
      "2025-07-04 17:38:54,924 - INFO - \n",
      "--- Обучение модели: GradientBoosting ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 19:53:18,159 - INFO - F1-weighted для GradientBoosting: 0.6144\n",
      "2025-07-04 19:53:18,310 - INFO - Лучшая модель (HistGradientBoosting) сохранена в: ./saved_models\\model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Пути и параметры\n",
    "TRAIN_DATA_PATH = './saved_datasets/train_combined.csv'\n",
    "MODEL_DIR = './saved_models'\n",
    "TARGET_COLUMN = 'risk_status'\n",
    "COLUMNS_TO_DROP = [\n",
    "    'week', 'user_id', 'course_id', 'real_course_progress', 'course_success'\n",
    "]\n",
    "\n",
    "# Гиперпараметры\n",
    "param_grids_config = {\n",
    "    \"RandomForest\": {\n",
    "        'n_estimators': [50, 100, 200, 300],\n",
    "        'max_depth': [10, 20, 30],\n",
    "        'max_features': ['sqrt']\n",
    "    },\n",
    "    \"GradientBoosting\": {\n",
    "        'n_estimators': [50, 100, 200], 'learning_rate': [0.05, 0.1],\n",
    "        'max_depth': [3, 5], 'subsample': [0.8]\n",
    "    },\n",
    "    \"CatBoost\": {\n",
    "        'iterations': [50, 100, 200], 'learning_rate': [0.05, 0.1],\n",
    "        'depth': [4, 6]\n",
    "    },\n",
    "    \"LightGBM\": {\n",
    "        'n_estimators': [50, 100, 200], 'learning_rate': [0.05, 0.1],\n",
    "        'max_depth': [5, 10], 'num_leaves': [31]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        'n_estimators': [50, 100, 200], 'learning_rate': [0.05, 0.1],\n",
    "        'max_depth': [3, 5], 'subsample': [0.8]\n",
    "    },\n",
    "    \"ExtraTrees\": {\n",
    "        'n_estimators': [50, 100, 200], 'max_depth': [10, 20],\n",
    "        'max_features': ['sqrt']\n",
    "    },\n",
    "    \"HistGradientBoosting\": {\n",
    "        'max_iter': [50, 100, 200], 'learning_rate': [0.05, 0.1],\n",
    "        'max_depth': [3, 5]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Загрузка данных\n",
    "train_df = pd.read_csv(TRAIN_DATA_PATH)\n",
    "\n",
    "# Обучение и сохранение лучшей модели\n",
    "trainer = ModelTrainer(\n",
    "    model_dir=MODEL_DIR,\n",
    "    param_grids=param_grids_config,\n",
    "    cv=5  # число фолдов кросс-валидации\n",
    ")\n",
    "trainer.train_and_save_best(\n",
    "    train_combined_df=train_df,\n",
    "    target_column=TARGET_COLUMN,\n",
    "    columns_to_drop=COLUMNS_TO_DROP\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
